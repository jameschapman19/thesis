\chapter{Conclusion}\label{ch:discussion}

This chapter provides a summary of the findings of this thesis, discusses their implications, and outlines potential directions for future work. 


\section{Summary of Contributions}
\subsection{Regularisation of CCA Models:
A Flexible Framework based on
Alternating Least Squares}
This chapter presented the FRALS framework for CCA, addressing challenges in analyzing large-scale neuroimaging datasets from projects such as the Human Connectome Project and the Alzheimer's Disease Neuroimaging Initiative. Incorporating structured priors through regularization, particularly the elastic net penalty, FRALS enhanced the interpretability and generalizability of CCA models. This method, documented in the work presented at the OHBM \citep{chapman2023als}, has been effective in uncovering significant brain-behavior associations, showing superior out-of-sample performance compared to traditional methods.

\subsection{Insights From Generating
Simulated Data for CCA}
This chapter contributed to the debate on the interpretation of model weights versus loadings in CCA. By generating high-dimensional simulated data and categorizing methods into explicit and implicit latent variable models, the chapter highlights the robustness of loadings to columnwise transformations in data matrices, a feature not shared with weights. The simulated data strategies formed part of the analysis in \citet{mihalik2022canonical} and influenced the analysis in \citet{ADAMS2024}.

\subsection{Efficient Algorithms for the
CCA Family: Unconstrained
Losses with Unbiased
Gradients}
Focusing on scaling challenges for CCA and PLS in the context of large-scale biomedical datasets like the UK Biobank, this chapter introduces a new gradient descent algorithm tailored for generalized eigenvalue problems. The methods developed, informed by publications \citep{chapman2022generalized, chapman2023efficient, chapman2023cca}, enable the application of multiview CCA and PLS to datasets with extensive dimensions and complex structures.

\subsection{Deep CCA and Self-Supervised
Learning}
This chapter introduces a novel formulation of Deep CCA optimized for the stochastic minibatch setting and proposes SSL-EY, a new competitive SSL method. Grounded in findings from \citep{chapman2023cca} and \citep{chapman2023efficient}, the chapter demonstrates the robustness of these methods against hyperparameter sensitivity and elucidates connections between CCA-based SSL methods and other contemporary SSL approaches.

\subsection{CCA-Zoo: A collection of
Regularized, Deep
Learning-based, Kernel, and
Probabilistic methods in a
scikit-learn style framework}
Presenting \texttt{CCA-Zoo}, a Python library that consolidates and enhances the accessibility of multiview learning methods, this chapter details the development and capabilities of the library, which implements a variety of CCA, PLS, and related techniques. As detailed in \citep{chapman2021cca}, \texttt{CCA-Zoo} addresses gaps in existing software offerings and facilitates broader adoption and innovation within the research community.

\section{Future Work}

\subsection{Applications}

One of the most rewarding aspects of this thesis has been seeing the software we developed, such as the CCA-Zoo package, being used by researchers across different fields to tackle a wide range of problems. It has been truly inspiring to witness the impact of our work and to see how it has enabled others to push the boundaries of multiview learning.

While the applications presented in this thesis, particularly the UK Biobank analysis in Chapter \ref{ch:deep_learning}, have demonstrated the potential of our methods, there is still vast untapped potential in applying these techniques to even larger and more diverse datasets. The ABCD dataset, for instance, offers a rich source of multimodal data that could benefit from the regularized and scalable CCA methods developed in this thesis. Preliminary results on this dataset have shown promise, and we believe that further exploration will yield valuable insights into brain development and its associated factors.

Moreover, the integration of non-imaging modalities, such as Electronic Health Records and audio transcripts, with neuroimaging data presents an exciting avenue for future research. The success of transformer architectures in natural language processing suggests that these methods could be powerful tools for analyzing and integrating textual and auditory data with brain imaging. By leveraging the capabilities of deep learning and the multiview learning framework of CCA, we can uncover complex relationships across modalities and gain a more comprehensive understanding of human health and behavior.

\subsection{Methods}

\subsubsection{Proximal Gradient Descent for CCA}

Preliminary experiments suggest that the proximal gradient descent approach is much faster than existing methods, making it a promising direction for future research. We anticipate that this methodology will significantly enhance the scalability and applicability of CCA, PCA, and PLS in the era of big data and complex regularization schemes.

\section{Closing Remarks}

As I reflect on my journey from struggling with the concepts of eigenvalues and eigenvectors as an undergraduate to delving into the intricacies of CCA as a doctoral researcher, I am struck by the depth and breadth of this field. Far from being a narrow topic, CCA has served as a gateway to explore a wide range of subjects, from optimization and Bayesian statistics to deep learning and software engineering.

One of the most exciting aspects of this journey has been witnessing the rapid growth and evolution of multiview and self-supervised learning during my PhD. The convergence of these fields with CCA has been truly remarkable, and I am thrilled to have been a part of this exciting development. The methods and insights gained from this thesis have the potential to contribute to the continued growth and impact of these areas.

I initially thought that my work would primarily focus on deep learning for brain-behavior associations. However, I quickly realized that existing methods for Deep CCA were not computationally feasible with existing methods for high-dimensional neuroimaging data. Additionally, I discovered that the complexity of the brain's relationship with observed mental health cannot be fully captured by even moderately sized datasets. This initially led me to instead look at efficient ways to regularize CCA models. However, I soon realized that the scalability of CCA was a significant bottleneck. This led me to develop efficient algorithms for CCA and PLS, which in turn led me to explore the connections between CCA and self-supervised learning. This journey has been both challenging and rewarding, and I am grateful for the opportunity to have worked on such exciting and impactful research.

Although we have been limited by access to data, particularly the UK Biobank with its tens of thousands of subjects, I am confident that the work presented in this thesis has made a meaningful impact on the field of multiview learning. As study sizes continue to increase and data collection costs decrease, I believe that machine learning methods, such as those developed in this thesis, will play a crucial role in understanding the intricate relationships between the brain and mental health.

The software tools we have developed, such as CCA-Zoo, have already been adopted by researchers across various domains, enabling them to push the boundaries of what is possible with CCA and related methods. With its rich history dating back to the 1930s, CCA has been a powerful tool for discovering new associations across various domains. The work presented in this thesis aims to contribute to the continued relevance and applicability of CCA in the era of big data and deep learning.

As we look to the future, I am excited by the prospects of further advancements in this field. The integration of deep learning with CCA, the application of these methods to ever-larger and more diverse datasets, and the potential for uncovering groundbreaking insights all point to a bright future for multiview learning. I hope that this thesis has not only made valuable contributions to the field but also inspired others to explore the fascinating world of CCA and its applications.

Thank you for reading.